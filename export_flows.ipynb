{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from datetime import time\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader(path, first_var):\n",
    "    '''\n",
    "    Reads SEMS/DASH data, adds datetime columns\n",
    "\n",
    "    :param path: path to data file\n",
    "    :param first_var: the name of the fir column label\n",
    "    :return: pandas DataFrame\n",
    "    '''\n",
    "    # Open the file and read the lines\n",
    "    skip=1\n",
    "    with open(path, \"r\") as file:\n",
    "        # Iterate over the lines\n",
    "        for line in file:\n",
    "            # rip leading and trailing whitespace\n",
    "            line = line.strip()\n",
    "            # Check if the line contains column names\n",
    "            if line.startswith(first_var):\n",
    "                # Split the line by whitespace and append to the columns list\n",
    "                columns = line[1:].strip().split(\"\\t\")\n",
    "                break\n",
    "            skip+=1\n",
    "    # Read the data into a DataFrame, skipping the first 6 rows of comments\n",
    "    d = pd.read_csv(path, sep='\\t', skiprows=skip, names=columns, low_memory=False)\n",
    "    #Check for duplicated metadata, remove metadata rows based on string \"OPC SN\"\n",
    "    if len(d)>0:\n",
    "        if isinstance(d.iloc[0,0], str):\n",
    "            dup_meta = [n for n, i in enumerate(d.iloc[:,0]) if 'OPC SN' in i]\n",
    "            if len(dup_meta) > 0:\n",
    "                for line in dup_meta:\n",
    "                    #Deletes duplicate metadata rows from dataframe\n",
    "                    d.drop(np.arange(line,line+68), inplace = True)\n",
    "                    # Apply the function to each column\n",
    "                    d_og = d.copy()\n",
    "                    for c in d.keys():\n",
    "                        try:\n",
    "                            d[c] = pd.to_numeric(d_og[c])\n",
    "                        except:\n",
    "                            d[c] = d_og[c]\n",
    "                    #d = d.apply(pd.to_numeric, ‘raise’,)\n",
    "                    \n",
    "    # Creates datetime columns\n",
    "    if 'DOY.Frac' in d.keys():\n",
    "        d['dt'] = pd.to_datetime('2024-1-1') + pd.to_timedelta(d['DOY.Frac'], unit='D') - pd.Timedelta(days=1)\n",
    "    if 'StartTimeSt' in d.keys():\n",
    "        d['st_dt'] = pd.to_datetime('2024-1-1') + pd.to_timedelta(d['StartTimeSt'], unit='D') - pd.Timedelta(days=1)\n",
    "    if 'EndTimeSt' in d.keys():\n",
    "        d['end_dt'] = pd.to_datetime('2024-1-1') + pd.to_timedelta(d['EndTimeSt'], unit='D') - pd.Timedelta(days=1)\n",
    "    if 'YY/MM/DD' and 'HR:MN:SC' in d.keys():\n",
    "        d['dt'] = pd.to_datetime(str(20) + d['YY/MM/DD'] + ' ' + d['HR:MN:SC'], format='%Y/%m/%d %H:%M:%S')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_reader(file_key, first_var, subfolder = './data/'):\n",
    "    '''\n",
    "    Reads groups of data files and merges them into one\n",
    "\n",
    "    :param file_key: shared key in filenames\n",
    "    :param first_var: the name of the first column label\n",
    "    :param subfolder: name of the subfolder containing the data\n",
    "    :return: pandas DataFrame\n",
    "    '''\n",
    "    paths = sorted(glob.glob(subfolder+'*'+file_key+'*'))\n",
    "    d = []\n",
    "    for i in range(0, len(paths)):\n",
    "        f = reader(paths[i], first_var)\n",
    "        if len(f)>0:\n",
    "            d.append(f)\n",
    "    d = pd.concat(d).reset_index()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_data():\n",
    "\n",
    "    folders = sorted(glob.glob('./data/DASH-flight*'))\n",
    "\n",
    "    dopc = []\n",
    "    hopc = []\n",
    "    dash = []\n",
    "    sems = []\n",
    "\n",
    "    for i in range(0, len(folders)):\n",
    "        path = folders[i] + '/'\n",
    "        dopc.append(glob_reader('OPC_212', '#YY/MM/DD', subfolder = path).drop_duplicates(subset='dt', keep='first'))\n",
    "        hopc.append(glob_reader('OPC_210', '#YY/MM/DD', subfolder = path).drop_duplicates(subset='dt', keep='first'))\n",
    "        dash.append(glob_reader('DASH_FLOW', '#DOY.Frac', subfolder = path).drop_duplicates(subset='dt', keep='first'))\n",
    "        sems.append(glob_reader('SEMS_DATA', '#DOY.Frac', subfolder = path).drop_duplicates(subset='dt', keep='first'))\n",
    "    \n",
    "    dopc = pd.concat(dopc, ignore_index=True)\n",
    "    hopc = pd.concat(hopc, ignore_index=True)\n",
    "    dash = pd.concat(dash, ignore_index=True)\n",
    "    sems = pd.concat(sems, ignore_index=True)\n",
    "    \n",
    "    # merge the DataFrames based on the DOPC times\n",
    "    merged = pd.merge_asof(dopc, hopc, on='dt', direction = 'nearest', tolerance=timedelta(seconds=1)).drop(columns=['index_x'])\n",
    "    merged = pd.merge_asof(merged, dash, on='dt', direction = 'nearest', tolerance=timedelta(seconds=1))\n",
    "    merged = pd.merge_asof(merged, sems, on='dt', direction = 'nearest', tolerance=timedelta(seconds=1))\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_flows(d):\n",
    "\n",
    "    # filter out for flight times\n",
    "    d_out = pd.DataFrame()\n",
    "    for _, row in ft.iterrows():\n",
    "        mask = (d['dt'] >= row['LARGE_Filter_Off_UTC']) & (d['dt'] <= row['LARGE_Filter_On_UTC'])\n",
    "        filtered = d[mask].copy()\n",
    "        d_out = pd.concat([d_out, filtered], ignore_index=True)\n",
    "    print(len(d_out))\n",
    "    d_out['input_flow_lpm'] = d_out['UpSt_Samp']\n",
    "\n",
    "    for i, row in ls.iterrows():\n",
    "        if row['LARGE_To'] == 'OFF':\n",
    "            mask = (d_out['dt'] >= row['Switch_Start_UTC']) & (d_out['dt'] <= ls.loc[i+1,'Switch_Stop_UTC'])\n",
    "            d_out.loc[mask,'input_flow_lpm'] = 0\n",
    "        elif row['LARGE_To'] == 'DASH':\n",
    "            mask = (d_out['dt'] >= row['Switch_Start_UTC']) & (d_out['dt'] <= row['Switch_Stop_UTC'])\n",
    "            d_out.loc[mask,'input_flow_lpm'] = 0\n",
    "            mask = (d_out['dt'] >= row['Switch_Stop_UTC']) & (d_out['dt'] <= ls.loc[i+1,'Switch_Stop_UTC'])\n",
    "            d_out.loc[mask,'input_flow_lpm'] = d_out.loc[mask,'HM_Smp_Xs']\n",
    "        elif row['LARGE_To'] == 'SEMS':\n",
    "            mask = (d_out['dt'] >= row['Switch_Start_UTC']) & (d_out['dt'] <= row['Switch_Stop_UTC'])\n",
    "            d_out.loc[mask,'input_flow_lpm'] = 0\n",
    "    \n",
    "    output = pd.DataFrame(data={'datetime_UTC':d_out['dt'], 'input_flow_lpm':d_out['input_flow_lpm']})\n",
    "\n",
    "    return output, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['HM_Smp_Xs'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214752"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507466\n"
     ]
    }
   ],
   "source": [
    "output, dout = retrieve_flows(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv('./meta/ARCSIX_takeoff_landing_times.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = pd.read_csv('./meta/ARCSIX_DASH_SEMS_switch_times.txt', parse_dates=['Switch_Start_UTC', 'Switch_Stop_UTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d) - len(d.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        -0.00\n",
       " 1        -0.00\n",
       " 2        -0.00\n",
       " 3        -0.00\n",
       " 4        -0.00\n",
       "           ... \n",
       " 214747    1.78\n",
       " 214748    1.78\n",
       " 214749    1.78\n",
       " 214750    1.78\n",
       " 214751    1.42\n",
       " Name: UpSt_Samp, Length: 214752, dtype: float64,\n",
       " 0        2024-05-28 08:50:21\n",
       " 1        2024-05-28 08:50:22\n",
       " 2        2024-05-28 08:50:23\n",
       " 3        2024-05-28 08:50:24\n",
       " 4        2024-05-28 08:50:26\n",
       "                  ...        \n",
       " 214747   2024-06-10 16:04:59\n",
       " 214748   2024-06-10 16:05:00\n",
       " 214749   2024-06-10 16:05:01\n",
       " 214750   2024-06-10 16:05:02\n",
       " 214751   2024-06-10 16:05:03\n",
       " Name: dt, Length: 214752, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['UpSt_Samp'], d['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YY/MM/DD_x',\n",
       " 'HR:MN:SC_x',\n",
       " 'samp_intrvl_x',\n",
       " 'total_conc_x',\n",
       " 'sample_flw_x',\n",
       " 'sheath_flw_x',\n",
       " 'sheath_temp_x',\n",
       " 'samp_press_x',\n",
       " 'lasr_brt_x',\n",
       " 'lasr_cur_x',\n",
       " 'pmt_base_rd_x',\n",
       " 'pmt_base_pot_adj_x',\n",
       " 'sheath_pwr_x',\n",
       " 'exit_pwr_x',\n",
       " 'opc_errs_x',\n",
       " 'bin1_x',\n",
       " 'bin2_x',\n",
       " 'bin3_x',\n",
       " 'bin4_x',\n",
       " 'bin5_x',\n",
       " 'bin6_x',\n",
       " 'bin7_x',\n",
       " 'bin8_x',\n",
       " 'bin9_x',\n",
       " 'bin10_x',\n",
       " 'bin11_x',\n",
       " 'bin12_x',\n",
       " 'bin13_x',\n",
       " 'bin14_x',\n",
       " 'bin15_x',\n",
       " 'bin16_x',\n",
       " 'bin17_x',\n",
       " 'bin18_x',\n",
       " 'bin19_x',\n",
       " 'bin20_x',\n",
       " 'bin21_x',\n",
       " 'bin22_x',\n",
       " 'bin23_x',\n",
       " 'bin24_x',\n",
       " 'bin25_x',\n",
       " 'bin26_x',\n",
       " 'bin27_x',\n",
       " 'bin28_x',\n",
       " 'bin29_x',\n",
       " 'bin30_x',\n",
       " 'bin31_x',\n",
       " 'bin32_x',\n",
       " 'bin33_x',\n",
       " 'bin34_x',\n",
       " 'bin35_x',\n",
       " 'bin36_x',\n",
       " 'bin37_x',\n",
       " 'bin38_x',\n",
       " 'bin39_x',\n",
       " 'bin40_x',\n",
       " 'bin41_x',\n",
       " 'bin42_x',\n",
       " 'bin43_x',\n",
       " 'bin44_x',\n",
       " 'bin45_x',\n",
       " 'bin46_x',\n",
       " 'bin47_x',\n",
       " 'bin48_x',\n",
       " 'bin49_x',\n",
       " 'bin50_x',\n",
       " 'bin51_x',\n",
       " 'bin52_x',\n",
       " 'bin53_x',\n",
       " 'bin54_x',\n",
       " 'bin55_x',\n",
       " 'bin56_x',\n",
       " 'bin57_x',\n",
       " 'bin58_x',\n",
       " 'bin59_x',\n",
       " 'bin60_x',\n",
       " 'bin61_x',\n",
       " 'bin62_x',\n",
       " 'bin63_x',\n",
       " 'bin64_x',\n",
       " 'bin65_x',\n",
       " 'bin66_x',\n",
       " 'bin67_x',\n",
       " 'bin68_x',\n",
       " 'bin69_x',\n",
       " 'bin70_x',\n",
       " 'bin71_x',\n",
       " 'bin72_x',\n",
       " 'sd_save_x',\n",
       " 'sd_install_x',\n",
       " 'dt',\n",
       " 'index_y',\n",
       " 'YY/MM/DD_y',\n",
       " 'HR:MN:SC_y',\n",
       " 'samp_intrvl_y',\n",
       " 'total_conc_y',\n",
       " 'sample_flw_y',\n",
       " 'sheath_flw_y',\n",
       " 'sheath_temp_y',\n",
       " 'samp_press_y',\n",
       " 'lasr_brt_y',\n",
       " 'lasr_cur_y',\n",
       " 'pmt_base_rd_y',\n",
       " 'pmt_base_pot_adj_y',\n",
       " 'sheath_pwr_y',\n",
       " 'exit_pwr_y',\n",
       " 'opc_errs_y',\n",
       " 'bin1_y',\n",
       " 'bin2_y',\n",
       " 'bin3_y',\n",
       " 'bin4_y',\n",
       " 'bin5_y',\n",
       " 'bin6_y',\n",
       " 'bin7_y',\n",
       " 'bin8_y',\n",
       " 'bin9_y',\n",
       " 'bin10_y',\n",
       " 'bin11_y',\n",
       " 'bin12_y',\n",
       " 'bin13_y',\n",
       " 'bin14_y',\n",
       " 'bin15_y',\n",
       " 'bin16_y',\n",
       " 'bin17_y',\n",
       " 'bin18_y',\n",
       " 'bin19_y',\n",
       " 'bin20_y',\n",
       " 'bin21_y',\n",
       " 'bin22_y',\n",
       " 'bin23_y',\n",
       " 'bin24_y',\n",
       " 'bin25_y',\n",
       " 'bin26_y',\n",
       " 'bin27_y',\n",
       " 'bin28_y',\n",
       " 'bin29_y',\n",
       " 'bin30_y',\n",
       " 'bin31_y',\n",
       " 'bin32_y',\n",
       " 'bin33_y',\n",
       " 'bin34_y',\n",
       " 'bin35_y',\n",
       " 'bin36_y',\n",
       " 'bin37_y',\n",
       " 'bin38_y',\n",
       " 'bin39_y',\n",
       " 'bin40_y',\n",
       " 'bin41_y',\n",
       " 'bin42_y',\n",
       " 'bin43_y',\n",
       " 'bin44_y',\n",
       " 'bin45_y',\n",
       " 'bin46_y',\n",
       " 'bin47_y',\n",
       " 'bin48_y',\n",
       " 'bin49_y',\n",
       " 'bin50_y',\n",
       " 'bin51_y',\n",
       " 'bin52_y',\n",
       " 'bin53_y',\n",
       " 'bin54_y',\n",
       " 'bin55_y',\n",
       " 'bin56_y',\n",
       " 'bin57_y',\n",
       " 'bin58_y',\n",
       " 'bin59_y',\n",
       " 'bin60_y',\n",
       " 'bin61_y',\n",
       " 'bin62_y',\n",
       " 'bin63_y',\n",
       " 'bin64_y',\n",
       " 'bin65_y',\n",
       " 'bin66_y',\n",
       " 'bin67_y',\n",
       " 'bin68_y',\n",
       " 'bin69_y',\n",
       " 'bin70_y',\n",
       " 'bin71_y',\n",
       " 'bin72_y',\n",
       " 'sd_save_y',\n",
       " 'sd_install_y',\n",
       " 'index_x',\n",
       " 'DOY.Frac_x',\n",
       " 'YYYY_x',\n",
       " 'Secs_x',\n",
       " 'DO_Sh',\n",
       " 'DO_Smp',\n",
       " 'DO_Press',\n",
       " 'DO_Ht_T',\n",
       " 'DO_Ht_Pwr',\n",
       " 'DO_Fl_T',\n",
       " 'DO_X_T',\n",
       " 'HO_Sh_D_Fl',\n",
       " 'HO_Sh',\n",
       " 'HO_Smp',\n",
       " 'HO_Press',\n",
       " 'HO_RH',\n",
       " 'HO_T',\n",
       " 'HO_Ht_T',\n",
       " 'HO_Ht_Pwr',\n",
       " 'HO_Fl_T',\n",
       " 'HO_X_T',\n",
       " 'HO_DP_Cl',\n",
       " 'HO_DP_Lk',\n",
       " 'HM_Sh_D_Fl',\n",
       " 'HM_Sh',\n",
       " 'HM_Xs',\n",
       " 'HM_Smp_Xs',\n",
       " 'HM_Press',\n",
       " 'HM_RH',\n",
       " 'HM_T',\n",
       " 'HM_Ht_T',\n",
       " 'HM_Ht_Pwr',\n",
       " 'HM_Fl_T',\n",
       " 'HM_X_T',\n",
       " 'HM_DP_Cl',\n",
       " 'HM_DP_Lk',\n",
       " 'H2O_T',\n",
       " 'H2O_Pwr',\n",
       " 'H2O_Lvl',\n",
       " 'H2O_Cnt',\n",
       " 'index_y',\n",
       " 'DOY.Frac_y',\n",
       " 'YYYY_y',\n",
       " 'Secs_y',\n",
       " 'UpSt_Sh',\n",
       " 'UpSt_Xs',\n",
       " 'UpSt_Samp',\n",
       " 'UpSt_FAdj',\n",
       " 'UpSt_Rh',\n",
       " 'UpSt_T',\n",
       " 'UpSt_Press',\n",
       " 'UpSt_Dia',\n",
       " 'UpSt_HV']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
